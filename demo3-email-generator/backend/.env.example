# Azure OpenAI Configuration for LLMs (GPT-4o, Grok, etc.)
AZURE_OPENAI_API_KEY=your_api_key_here
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4o
AZURE_OPENAI_API_VERSION=2024-08-01-preview

# Grok Code Fast for HTML/code generation (optional - defaults to grok-code-fast-1)
CODE_DEPLOYMENT=grok-code-fast-1

# Azure OpenAI Embeddings for RAG (optional - RAG disabled if not set)
AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT=text-embedding-ada-002

# Image Generation Configuration
# Provider selection: dalle (default), gpt-4o, gemini (nano-banana!), stability, fallback (text only)
IMAGE_PROVIDER=dalle

# Image Generation Deployment (when IMAGE_PROVIDER=dalle)
# Supports both URL-based (DALL-E 3) and base64-based (FLUX-1.1-pro) responses
# If image deployment is in a different Azure resource, set these separately:
IMAGE_API_KEY=your_image_api_key_here
IMAGE_ENDPOINT_URL=https://your-image-resource.openai.azure.com/
IMAGE_API_VERSION=2024-02-01
IMAGE_DEPLOYMENT_NAME=dall-e-3  # or FLUX-1.1-pro, or any other image model

# If DALL-E is in the SAME resource, you can omit IMAGE_* vars
# (they will fall back to the main AZURE_OPENAI_* values)

# Gemini 2.5 Flash Image (when IMAGE_PROVIDER=gemini or nano-banana)
# Get your API key from: https://aistudio.google.com/apikey
GOOGLE_API_KEY=your_google_api_key_here

# Alternative providers (when IMAGE_PROVIDER is set to something other than dalle):
# STABILITY_API_KEY=your_stability_key_here

# LangSmith Tracing (optional - for debugging and monitoring LangChain operations)
# Get your API key from: https://smith.langchain.com/settings
# LANGCHAIN_TRACING_V2=true
# LANGCHAIN_API_KEY=your_langsmith_api_key_here
# LANGCHAIN_PROJECT=demo3-email-generator

# Server Configuration
PORT=3003
